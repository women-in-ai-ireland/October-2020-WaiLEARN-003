{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.preprocessing import image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 33, 33, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 1,704,097\n",
      "Trainable params: 1,704,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  \n",
    "    # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  \n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "  \n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "  \n",
    "    # The fourth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "  \n",
    "    # The fifth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "  \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'), # 512 neuron hidden layer\n",
    "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for ('normal') clas and 1 for ('pneumonia') class\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# to get the summary of the model\n",
    "model.summary()\n",
    "\n",
    "# configure the model for traning by adding metrics\n",
    "model.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=0.001), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1860 images belonging to 2 classes.\n",
      "Found 1860 images belonging to 2 classes.\n",
      "Epoch 1/8\n",
      "2/2 [==============================] - 172s 86s/step - loss: 0.7726 - accuracy: 0.4414 - val_loss: 0.6962 - val_accuracy: 0.5000\n",
      "Epoch 2/8\n",
      "2/2 [==============================] - 163s 81s/step - loss: 0.7024 - accuracy: 0.4219 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 3/8\n",
      "2/2 [==============================] - 130s 65s/step - loss: 0.6930 - accuracy: 0.5312 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 4/8\n",
      "2/2 [==============================] - 121s 61s/step - loss: 0.6957 - accuracy: 0.4643 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 5/8\n",
      "2/2 [==============================] - 124s 62s/step - loss: 0.6936 - accuracy: 0.4766 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 6/8\n",
      "2/2 [==============================] - 117s 59s/step - loss: 0.6934 - accuracy: 0.5039 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 7/8\n",
      "2/2 [==============================] - 120s 60s/step - loss: 0.6917 - accuracy: 0.5664 - val_loss: 0.6939 - val_accuracy: 0.5000\n",
      "Epoch 8/8\n",
      "2/2 [==============================] - 127s 64s/step - loss: 0.6878 - accuracy: 0.5625 - val_loss: 0.6989 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1/255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '../covid-wai-project/covid-chestxray-dataset-master/images_test/',\n",
    "    target_size = (300,300),\n",
    "    batch_size = 128,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    '../covid-wai-project/covid-chestxray-dataset-master/images_test/',\n",
    "    target_size = (300, 300),\n",
    "    batch_size = 128,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "\n",
    "# training the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 2,\n",
    "    epochs = 8,\n",
    "    validation_data = validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
